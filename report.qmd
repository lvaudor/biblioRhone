---
title: "BiblioRhone"
format: 
  html:
    toc: true
    toc_float: true
editor: visual
execute:
  cache: true
  echo: false
  message: false
---

```{r load_packages}
# Chargement des packages et des données
library(tidyverse)
library(bibliometrix)
```

```{r load_data_bibliometrix,message=FALSE, warning=FALSE}
file <- "data/savedrecs.bib"
M <- convert2df(file = file, dbsource = "isi", format = "bibtex")
results <- biblioAnalysis(M, sep = ";")
```

```{r tib_doc}
tib_doc=M %>%
  rownames_to_column(var="id_doc") %>% 
  as_tibble()
```

```{r tib_auteur}
tib_auteur=tib_doc %>% 
  group_by(id_doc) %>% 
  nest() %>% 
  mutate(data=purrr::map(data,
                         ~mutate(.x,
                                 AU=str_split(AU,";")))) %>%
  mutate(data=purrr::map(data,
                         ~unnest(.x, cols=c("AU")))) %>% 
  unnest(cols="data") %>% 
  mutate(AU_rank=1:n()) %>% 
  ungroup() 
```

```{r tib_motscles}
tib_motscles= tib_doc %>% 
  group_by(id_doc) %>% 
  nest() %>% 
  mutate(data=purrr::map(data,
                         ~mutate(.x,DE=str_split(DE,";")))) %>% 
  mutate(data=purrr::map(data,
                         ~unnest(.x, cols="DE"))) %>% 
  unnest(cols="data") %>% 
  ungroup() 
```

# Analyses simples, "à plat"

### Auteurs 

- ndoc nombre de documents (dans ce corpus):
- ncit nombre de citations (globales)
- ndoc_1st nombre de documents en tant que 1er auteur
- ncit_1st nombre de citations en tant que 1er auteur
- ncit_loc: nombre de citations locales (i.e. par les document de ce corpus)


```{r locallyCitedAuthors}
LCR=localCitations(M)
#LCR$Authors$Author liste des auteurs cités dans le champ M$CR
#Combien de fois chacun de ces auteurs apparaît dans M$CR?
#Attention ce résultat ne correspond pas à celui renvoyé par localCitations() voir objet LCR
aut_loc=LCR$Authors %>% 
  as_tibble() %>% 
  select(Author) %>% 
  filter(!(Author %in% c("DE","LE","VAN","[ANONYMOUS] A"))) %>% 
  mutate(ncit_loc=purrr::map_int(Author, ~length(which(str_detect(M$CR,.x)))))
```



```{r auteurs}
auteurs=tib_auteur %>% 
  group_by(AU) %>% 
  mutate(ndoc=n(),
         ncit=sum(TC)) %>%
  filter(AU_rank==1) %>% 
  summarise(ndoc=unique(ndoc),
            ncit=unique(ncit),
            ndoc_1st=n(),
            ncit_1st=sum(TC)) %>%
  ungroup() %>% 
  left_join(aut_loc,by=c("AU"="Author")) %>% 
  arrange(desc(ndoc)) 
reactable::reactable(auteurs)
```


### Sources 

- ndoc: nombre de documents
- ncit: nombre de citations (totales)

```{r sources}
sources=tib_doc %>% 
  group_by(SO) %>% 
  summarise(ndoc=n(),
            ncit=sum(TC)) %>%
  arrange(desc(ndoc))
reactable::reactable(sources)
```

### Documents

```{r top_10_articles}
show_docs=tib_doc %>% 
  arrange(desc(TC)) %>% 
  select(AU,PY,TI,SO)
reactable::reactable(show_docs)
```

### Références

Les articles du corpus font référence à des documents locaux (du corpus) ou externes. 

*Attention* Une partie (minime: ~0.7%) de ces références est mal renseignée par WOS. Celles qui sont correctement renseignées de manière correcte le sont de telle sorte qu'il est difficile de faire une jointure pour retrouver les références locales.

```{r bad_citations}
cit=citations(M)
cit$Cited %>% as_tibble %>%
  summarise(nref=sum(n),
            nref_distinctes=n(),
            nref_pb=length(which(str_detect(CR,"ANONYMOUS"))))
```
Top 20 des articles les plus cités:

```{r}
cit$Cited %>%
  as_tibble() %>% 
  filter(!str_detect(CR,"ANONYMOUS")) %>% 
  head(n=20)
```


### Affiliations

bibliometrix comprend des fonctions permettant d'extraire automatiquement les éléments d'affiliation distincts et les références mais ça fonctionne moyen (de fait il est déjà assez difficile d'en faire sens au niveau de l'export WOS...)

```{r affiliations}
aff=results$Affiliations %>%
  as_tibble() %>% 
  head(n=50)
reactable::reactable(aff)
```

Il est ainsi assez difficile de travailler sur les affiliations de manière "non dirigée"... Par exemple pour les publis Hervé et en filtrant pour garder les publis récentes (>2005) on a déjà 34 affiliations formulées de manière différentes (tout est mélangé pour les différents auteurs des articles) et en fonction du champ l'info principale n'est pas toujours la même (ici pas de mention de EVS par ex.).   

<!-- ```{r aff_piegay} -->
<!-- aff_piegay=tib_auteur %>%  -->
<!--   filter(AU=="PIEGAY H" & PY>2005) %>%  -->
<!--   select(affiliations) %>%  -->
<!--   unique() -->
<!-- reactable::reactable(aff_piegay) -->
<!-- ``` -->

Par contre on pourrait imaginer lister un certain nombre de structures (CNRS, EVS, LBBE, LEHNA, etc) et tenter de détecter à partir de cet ensemble quels auteurs/publis s'y rattachent...

### Financement

Des infos sont enregistrées dans la base de données WOS concernant les programmes de recherche et les sources de financement. On peut récupérer ces renseignements pour environ un tiers des documents. Si on veut s'en servir il y aura un peu de nettoyage à faire...

```{r funding}
bib=bibtex::read.bib("data/savedrecs.bib")
bibtib=tibble(WOS_ID=names(bib),
              funding_text=NA,
              funding_acknowledgement=NA)
for(i in 1:length(bib)){
  biblist=unlist(bib[i])
  var_text=paste0(bibtib$WOS_ID[i],".funding-text")
  var_ackn=paste0(bibtib$WOS_ID[i],".funding-acknowledgement")
  if(var_text %in% names(biblist)){
    bibtib$funding_text[i]=biblist[[var_text]]
  }else{
    bibtib$funding_text[i]=NA
  }
  if(var_ackn %in% names(biblist)){
    bibtib$funding_acknowledgement[i]=biblist[[var_ackn]]
  }else{
    bibtib$funding_acknowledgement[i]=NA
  }
}
```

```{r financeurs}
financeurs=bibtib %>% 
  filter(!is.na(funding_acknowledgement)) %>% 
  group_by(funding_acknowledgement) %>% 
  summarise(ndoc=n()) %>% 
  arrange(desc(ndoc))
reactable::reactable(financeurs)
```



## Nombre de publis par année (dans le corpus)

```{r ndoc_per_year}
ggplot(tib_doc,
       aes(x=PY))+
  geom_bar()+
  xlab("année de publication")+ylab("nombre de publications")
```

```{r aut_prod_over_time}
topAU <- authorProdOverTime(M, k = 20, graph = TRUE)
```

# Graphes biblio

`biblioNetwork()` uses two arguments to define the network to compute:

- **analysis** argument can be "co-citation", "coupling", "collaboration", or "co-occurrences".
- **network** argument can be "authors", "references", "sources", "countries", "universities", "keywords", "author_keywords", "titles" and "abstracts".



## Collaborations (auteurs)


```{r calc_collaboration_graph}
NetMatrix <- biblioNetwork(M,
                           analysis = "collaboration",
                           network = "authors",
                           sep = ";")

```

```{r plot_collaboration_graph, fig.width=6,fig.height=6}
net=networkPlot(NetMatrix,
                normalize = "salton", 
                weighted=NULL,
                n = 100,
                Title = "Collaboration",
                type = "fruchterman",
                size=5,
                size.cex=T,
                remove.multiple=TRUE,
                labelsize=0.8,
                label.n=50,
                label.cex=F)

```



## Co-Citation 

```{r co_citation_network, fig.width=8, fig.height=8}
M=M %>% 
  mutate(CR=str_replace(CR,"ANONYMOUS.*;","")) %>% 
  mutate(CR=str_replace(CR,"NO TITLE CAPTURED","")) 
NetMatrix <- biblioNetwork(M,
                           analysis = "co-citation",
                           network = "references",
                           sep = ";")

net=networkPlot(NetMatrix,
                n = 150,
                Title = "Co-Citation Network",
                type = "fruchterman",
                size=T,
                remove.multiple=FALSE,
                labelsize=0.7,edgesize = 5,
                label.n=30)
```

## Co-occurrences de mots-clés

```{r calc_graph_keywords}
NetMatrix <- biblioNetwork(M,
                           analysis = "co-occurrences",
                           network = "keywords",
                           sep = ";")
netstat <- networkStat(NetMatrix)
```

```{r plot_graph_keywords, fig.width=6, fig.height=6}
net=networkPlot(NetMatrix,
                weighted=T, n = 150,
                Title = "Keyword Co-occurrences",
                type = "fruchterman",
                cluster="leading_eigen",
                size=T,
                edgesize = 5,
                labelsize=0.7)
```


## Historical Direct Citation Network

The historiographic map is a graph proposed by E. Garfield (2004) to represent a chronological network map of most relevant direct citations resulting from a bibliographic collection.

Garfield, E. (2004). Historiographic mapping of knowledge domains literature. Journal of Information Science, 30(2), 119-145.

The function generates a chronological direct citation network matrix which can be plotted using histPlot:

## Create a historical citation network

```{r histnetwork,fig.height=10,fig.width=10}
histResults <- histNetwork(M, min.citations = 1, sep = ";")

net <- histPlot(histResults, n=150, size = 1, labelsize=5, verbose=FALSE)
net$g+theme(legend.position="none")
```


## Co-Word Analysis: The conceptual structure of a field

The aim of the co-word analysis is to map the conceptual structure of a framework using the word co-occurrences in a bibliographic collection.

The analysis can be performed through dimensionality reduction techniques such as Multidimensional Scaling (MDS), Correspondence Analysis (CA) or Multiple Correspondence Analysis (MCA).

Here, we show an example using the function conceptualStructure that performs a CA or MCA to draw a conceptual structure of the field and K-means clustering to identify clusters of documents which express common concepts. Results are plotted on a two-dimensional map.

conceptualStructure includes natural language processing (NLP) routines (see the function termExtraction) to extract terms from titles and abstracts. In addition, it implements the Porter's stemming algorithm to reduce inflected (or sometimes derived) words to their word stem, base or root form.

## Conceptual Structure using keywords (method="CA")

```{r conceptual_structure}
CS <- conceptualStructure(M,
                          field="ID",
                          method="CA",
                          minDegree=4,
                          clust=8,
                          stemming=FALSE,
                          labelsize=10,
                          documents=10)
```


# Analyse textuelle des abstracts

## Etapes méthodo

### Mise en forme de la base

```{r tib_textes}
library(tidytext)
tib_textes=as_tibble(M) %>% 
  select(TI,AU,SO,DT,DE,TC,PY,AB) %>% 
  mutate(document=1:n())
tib_meta=tib_textes %>% select(-AB)
```

### Tokenisation, lemmatisation:

```{r token_lemma}
tib_lemma=tib_textes %>% 
  unnest_tokens(word,AB,token="words")

lex_en=mixr::get_lexicon("en")
tib_lemma_cl=left_join(tib_lemma, lex_en,by="word") %>% 
  filter(type %in% c("nom","ver","adj"))
```

### mise en forme pour STM

```{r cast_sparse}
tib_sparse=tib_lemma_cl %>% 
  group_by(lemma) %>% # compte pour chaque lemme...
  mutate(n=n()) %>% # ...son nombre d'occurrences puis
  filter(n>20) %>%  # retire ceux représentés moins de 20 fois dans le corpus
  ungroup() %>% 
  cast_sparse(row=TI, column=lemma, value=n)
```

## STM

```{r stm}
library(stm)
set.seed(123)
topic_model<-stm(tib_sparse,K=8, verbose=FALSE)
```

## Explore thématiques

```{r termes_thematiques}
termes_thematiques=tidy(topic_model, matrix="beta") %>% 
  group_by(topic) %>% 
  slice_max(beta,n=20) %>%  
  mutate(rank=row_number()) %>% 
  arrange(topic,desc(beta)) %>% 
  ungroup()
```

```{r plot_termes_thematiques, fig.width=8, fig.height=8}
ggplot(termes_thematiques  %>%
         mutate(topic=as.factor(topic)) %>%
         mutate(term=reorder_within(term,by=beta,within=topic)),
       aes(x=beta,y=term, fill=topic))+
  geom_bar(stat="identity")+
    facet_wrap(facets=vars(topic), scales="free")+
    theme(legend.position="none")+
  scale_y_reordered()
```

```{r tib_gamma}
tib_gamma <- tidy(topic_model, matrix = "gamma") %>% 
  arrange(document,desc(gamma))
```

```{r thematiques}
thematiques=termes_thematiques %>% 
  group_by(topic) %>% 
  nest()%>%  
  summarise(topic_terms=map(data, ~paste(.$term,collapse=", "))) %>% 
  unnest(cols=c(topic_terms))
```

```{r tib_meta_thematiques}
tib_meta_thematiques=tib_meta  %>%
  left_join(tib_gamma) %>% 
  left_join(thematiques,by="topic") %>% 
         group_by(PY,topic,topic_terms) %>% 
         summarise(sgamma=sum(gamma)) %>% 
         ungroup() %>% 
         na.omit()
ggplot(tib_meta_thematiques,
       aes(x=PY,y=sgamma,col=factor(topic)))+
  geom_path()+
  facet_grid(rows=vars(topic_terms))
```
