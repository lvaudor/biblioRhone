---
title: "BiblioRhone"
format: 
  html:
    code-fold: true
    toc: true
    toc_float: true
    out-width: "100%"
    fig-width: 6
    fig-height: 5
editor: visual
execute:
  message: false
  warning: false
  cache: true
---

Chapitre introductif d'un ouvrage sur la recherche sur le Rhône (20 ans de ZABR-OHM). Création de:

-   ZABR 2000
-   OHM 2011

```{r setup, message=FALSE, warning=FALSE}
# Chargement des packages et des données
library(tidyverse)
library(magrittr)
library(bibliometrix)
library(ggraph)
#library(tidygraph)
library(tidytext)
library(mixr)
library(bibou)
set.seed(123)
```

Import et nettoyage de la base .bib (exporté depuis Web of Science).

Dans titre ou topic: "Rhone" & "river\|basin\|catchment". Filtre ultérieur pour retirer les mentions de Rhone présentes seulement dans les "Keywords +" (issus d'un algorithme de Web of Science reposant en partie sur les références biblio des documents)

```{r clean_savedrecs_Rhone}
if(!file.exists("data/M.RDS")){
  bibou::bib_remove_duplicates("data-raw/savedrecs_Rhone.bib")
  M=bibliometrix::convert2df(file = "data-raw/savedrecs_Rhone.bib",
                  dbsource = "isi",
                  format = "bibtex")
  tib_doc=bibou::bib_tib_doc("data-raw/savedrecs_Rhone_clean.bib",
                           check_in_text="RHONE") %>% 
    mutate(condition=PY>2018 & str_detect(AU, "ARNAUD F")) %>% 
    mutate(AU=case_when(condition~str_replace_all(AU,"ARNAUD F","ARNAUD Fa"),
                        TRUE~AU),
           id_doc=case_when(condition~str_replace_all(id_doc,"ARNAUD F","ARNAUD Fa"),
                            TRUE~id_doc))
  saveRDS(M,"data/M.RDS")
  saveRDS(tib_doc,"data/tib_doc.RDS")
}
M=readRDS("data/M.RDS")
tib_doc=readRDS("data/tib_doc.RDS")
```


```{r tib_doc_derived}
if(!file.exists("data/tib_doc_AU.RDS")){
  tib_doc_AU=bibou::bib_tib_doc_AU(tib_doc)
  tib_doc_CR=bibou::bib_tib_doc_CR(tib_doc)
  tib_doc_DE=bibou::bib_tib_doc_DE(tib_doc)
  tib_doc_ABW=bibou::bib_tib_doc_ABW(tib_doc)
  saveRDS(tib_doc_AU,"data/tib_doc_AU.RDS")
  saveRDS(tib_doc_CR,"data/tib_doc_CR.RDS")
  saveRDS(tib_doc_DE,"data/tib_doc_DE.RDS")
  saveRDS(tib_doc_ABW,"data/tib_doc_ABW.RDS")
}
tib_doc_AU=readRDS("data/tib_doc_AU.RDS")
tib_doc_CR=readRDS("data/tib_doc_CR.RDS")
tib_doc_DE=readRDS("data/tib_doc_DE.RDS")
tib_doc_ABW=readRDS("data/tib_doc_ABW.RDS")
```

# Analyses simples, "à plat"

### Documents

### Auteurs


On attribue au $k$-ième auteur d'un document qui en compte $n$ en tout un poids $w$ de

$$w=(n-k+1)\frac{2}{n(n+1)}$$ soit par exemple pour un document qui compte 4 auteurs des poids de 0.4,0.3,0.2 et 0.1 pour le premier, deuxième, troisième et quatrième auteur respectivement.


```{r auteurs}
auteurs=tib_doc_AU %>% 
  group_by(AU) %>% 
  summarise(ndoc=n(),
            ndocw=sum(AU_weight),
            TC=sum(TC),
            TCw=sum(TC*AU_weight),
            LC=sum(LC),
            LCw=sum(LC*AU_weight),.groups="drop")
```

Le corpus compte `r nrow(auteurs)` auteurs distincts. Un auteur est associé à en moyenne `r mean(auteurs$ndoc)` documents du corpus. `r nrow(dplyr::filter(auteurs,ndoc>=2))` sont associés à au moins 2 documents, `r nrow(dplyr::filter(auteurs,ndoc>=5))` sont associés à au moins 5 documents.

-   **ndoc** nombre de documents (dans ce corpus):
-   **TC** nombre de citations (globales)
-   **LC** nombre de citations locales (par les autres articles du corpus)

```{r barplot_ndocs_aut, fig.height=3,fig.width=4}
ggplot(auteurs, aes(x=ndoc)) +
  geom_bar()+
  xlab("distribution du nombre de documents par auteur")
```

```{r top_authors}
#| label: fig-plot_top20_auteurs
#| fig-cap: Top 20 des auteurs les plus productifs, en termes de a) nombre de documents b) nombre de fois où ses documents sont cités, c) nombre de fois où ses documents sont cités localement (i.e. par les autres documents du corpus). Ces trois mesures sont à chaque fois pondérées en fonction de la position de la personne dans la liste des auteurs.
p1=mixr::plot_frequencies(auteurs %>% arrange(desc(ndocw)) %>% head(20),
                       AU,freq=ndocw)
p2=mixr::plot_frequencies(auteurs %>% arrange(desc(TCw)) %>% head(20),
                       AU,freq=TCw)
p3=mixr::plot_frequencies(auteurs %>% arrange(desc(LCw)) %>% head(20),
                       AU,freq=LCw)
ggpubr::ggarrange(p1,p2,p3,nrow=1,labels=c("a","b","c"))
```




### Sources

```{r sources}
sources=mixr::tidy_frequencies(tib_doc,SO,top_freq=20)
```

### Références

Top 100 des articles les plus cités **par** le corpus:

```{r citations}
citations=tib_doc_CR %>% 
  mixr::tidy_frequencies(CR,top_freq=100)
reactable::reactable(citations,
                     filterable=TRUE)
```

## Nombre de documents par année (dans le corpus) et nombre de d'auteurs moyen par document

```{r ndoc_per_year, fig.width=6, fig.height=4}
#| label: fig-plot_nbdoc_temps
#| fig-cap: Evolution au cours du temps a) du nombre de publications et b) du nombre moyen d'auteurs par publication.
p1=ggplot(tib_doc,
       aes(x=PY))+
  geom_bar()+
  xlab("") + ylab("nb_publis")
nb_AU_doc_PY=tib_doc_AU %>% 
  group_by(PY,id_doc) %>% 
  summarise(n_AU=n(),.groups="drop") %>% 
  group_by(PY) %>% 
  summarise(n_AU=mean(n_AU),.groups="drop",
            n=n())
p2=ggplot(nb_AU_doc_PY, aes(x=PY,y=n_AU))+
   geom_path(color="red")+
   xlab("année de publication")+
   ylab("moy_nb_aut")
ggpubr::ggarrange(p1,p2,nrow=2,labels=c("a","b"))
```

## Comparaison à deux autres corpora

```{r Rhine_Rhone_Danube,fig.width=6, fig.height=5}
#| label: fig-plot_3corpus_temps
#| fig-cap: Evolution des publications dans 3 corpus constitués selon la même requête, mais pour 3 fleuves différents (a) Danube, b) Rhin, c) Rhône). Les courbes correspondent aux valeurs attendues si les publications étaient réparties de manière homogène entre les 3 corpus.
if(!file.exists("data-raw/tib_doc_Rhine.RDS")){
  for (river in c("Rhine","Rhone","Danube")){
    file <- glue::glue("data-raw/savedrecs_{river}_clean.bib")
    M <- convert2df(file = file,
                    dbsource = "isi",
                    format = "bibtex")
    tib_doc=M %>%
      rownames_to_column(var="id_doc") %>% 
      as_tibble() %>% 
      tidyr::unite(texts,TI,AB,DE,sep="; ",remove=FALSE) %>%
      mutate(rightriver=str_detect(texts,toupper(river))) %>%
      filter(rightriver) %>%
      select(-rightriver,-texts) %>%
      unique()
    saveRDS(tib_doc,glue::glue("data-raw/tib_doc_{river}.RDS"))
  }
}

tib_nb_publ_per_year=
  bind_rows(readRDS("data-raw/tib_doc_Rhone.RDS") %>% mutate(river="Rhone") %>% select(river,PY),
            readRDS("data-raw/tib_doc_Danube.RDS") %>% mutate(river="Danube") %>% select(river,PY),
            readRDS("data-raw/tib_doc_Rhine.RDS") %>% mutate(river="Rhine") %>% select(river,PY)) %>% 
  mutate(period=cut(PY,breaks=c(1940,2000,2011,2023),dig.lab=4)) %>% 
  mutate(period=as.factor(period)) %>% 
  mutate(ntot=n()) %>% 
  group_by(river) %>% 
  mutate(ndocriver=n()) %>% 
  ungroup() %>% 
  group_by(period) %>% 
  group_by(PY) %>% 
  mutate(ndocPY=n()) %>% 
  ungroup() %>% 
  mutate(predprop=ntot*(ndocriver/ntot)*(ndocPY/ntot)) %>% 
  arrange(river,PY) %>% 
  group_by(river,PY,predprop) %>% 
  summarise(n=n(),.groups="drop")
ggplot(tib_nb_publ_per_year,
       aes(x=PY,y=n))+
  geom_path(aes(y=predprop))+
  geom_col(alpha=0.5)+
  xlab("année de publication")+ylab("nombre de publications")+
  facet_grid(rows=vars(river),scales="free_y")+
  scale_x_continuous(limits=c(1980,2024))
```


## Focus sur les SHS

Quels sont les documents qui font mention des termes SOCIAL/SOCIETY/SOCIO-quelque-chose dans leur abstract?

```{r focus_SHS}
tib_doc =tib_doc %>% 
              mutate(mention_SHS=str_detect(AB,"SOCIAL|SOCIETY|SOCIO")) 
tib_doc_ABW=tib_doc_ABW %>% 
  left_join(tib_doc %>% 
              select(id_doc,mention_SHS),
            by="id_doc")

prop_SHS=tib_doc %>% 
  group_by(mention_SHS) %>%
  tally()
prop_SHS

```

**Peu de documents étiquetés "SHS" a priori** (`r round(prop_SHS$n[2]/(prop_SHS$n[1]+prop_SHS$n[2])*100,2)`% des documents pour lesquels on dispose de l'abstract) mais ce premier ensemble va nous permettre de rechercher les **termes spécifiques aux SHS** et d'identifier un "courant SHS" plus important et transverse (cf partie @sec-spec_SHS). Les termes en question montrent que l'intégration d'enjeux sociaux ou humains dans le corpus prennent le plus souvent la forme d'un intérêt pour la question de la **gestion des territoires**.

# Graphes biblio

## Réseaux d'auteurs

On définit des **communautés d'auteurs** en se basant sur les collaborations (co-signature de documents). 

On utilise ici la méthode de Louvain pour assigner chacun des auteurs à une communauté. Cette méthode est basée sur la maximisation de la modularité, qui mesure la qualité de la partition des noeuds en communautés. La méthode de Louvain est une méthode de partitionnement hiérarchique qui permet de trouver des communautés de taille variable. Elle est très rapide et permet de trouver des communautés de grande taille.

Lancichinetti, A., & Fortunato, S. (2009). Community detection algorithms: a comparative analysis. Physical review E, 80(5), 056117.

```{r calc_collaboration_graph}
nw_coll_auth <- biblioNetwork(M,
                           analysis = "collaboration",
                           network = "authors",
                           sep = ";")
```

```{r plot_collaboration_graph, fig.width=7,fig.height=6}
set.seed(12345)
p=networkPlot(nw_coll_auth,
            Title = "Collaborations",
            type = "fruchterman",
            cluster="louvain",
            size=5,
            size.cex=T,
            labelsize=0.5,
            label.n=30,
            label.cex=F,
            alpha=0.5,
            #remove.isolates=TRUE,
            #edges.min=1,
            verbose=FALSE,
            community.repulsion=0)
```

```{r}
auteurs=auteurs %>%
  mutate(au=tolower(AU)) %>% 
  left_join(p$cluster_res,by=c("au"="vertex")) %>% 
  mutate(cluster=paste0("cluster",str_pad(cluster,4)))

tib_cluster_commus=auteurs %>% 
  group_by(cluster) %>% 
  summarise(sum_ndocw=sum(ndocw),
            sum_ndoc=sum(ndoc)) %>% 
  arrange(desc(sum_ndocw)) %>% 
  mutate(rank=1:n()) %>% 
  mutate(community=case_when(rank<=12~paste0("c",str_pad(1:n(),pad="0",width=2)),
                             TRUE~NA_character_))

auteurs=auteurs %>% 
  left_join(tib_cluster_commus %>%
              select(cluster,community),
            by="cluster")
```

A ce stade, de nombreuses communautés (`r length(unique(auteurs$cluster))`) sont définies. Pour la suite de l'analyse on ne **conservera que les communautés à l'origine des 12 plus grands ensembles de documents** (ndoc > `r floor(tib_cluster_commus$sum_ndoc[12])` et ndocw > `r floor(tib_cluster_commus$sum_ndocw[12])`). Ainsi certains auteurs ne seront pas rattachés à une communauté.

## Rattachement des articles à une communauté {#sec-docs_commu}

La communauté se réfère aux auteurs (un auteur = zéro ou une communauté). Un document est ainsi potentiellement issu de zéro, une, ou plusieurs communautés. On calcule ci-dessous un **indice de diversité** (score de Shannon) pour chaque document, qui mesure la diversité des communautés d'auteurs qui ont contribué à un document donné. J'affiche les 50 documents pour lesquels cet indice est le plus élevé:

```{r docs_comm_diversity}
tib_doc_commus=tib_doc_AU %>% 
  select(id_doc,AU,AU_rank,AU_weight) %>%
  left_join(auteurs %>% select(AU,community),by="AU") %>%
  group_by(id_doc,community) %>% 
  summarise(weight=sum(AU_weight,na.rm=TRUE),.groups="drop")

shannon=function(P){-sum(log(P) * P, na.rm = TRUE)}
tib_doc_divers= tib_doc_commus %>% 
  group_by(id_doc) %>% 
  mutate(commu_label=purrr::map2(community,weight,~paste0(.x,":",.y))) %>% 
  summarise(diversity=shannon(weight),
            commu_label=paste(commu_label, collapse="; ")) %>% 
  arrange(desc(diversity)) %>% 
  left_join(tib_doc %>% select(id_doc,AU),by="id_doc") %>% 
  head(50)

reactable::reactable(tib_doc_divers,
                     filterable=TRUE,
                     resizable=TRUE)
```


Par la suite, on va **réassigner chaque document à une seule communauté** (la communauté qui a le poids le plus important pour cet article). 

Dans le cas où la majorité des auteurs ne fait pas partie d'une communauté définie, on assigne le document à la communauté majoritaire (par exemple si 30% des auteurs font partie de la communauté Cl01 et 70% ne font pas partie d'une communauté définie on assigne le document à la communauté Cl01).

```{r docs_comm}
tib_doc_commus=tib_doc %>% 
  left_join(tib_doc_commus,by=c("id_doc"))
```


```{r tib_commus_prod}
tib_commus_prod= tib_doc_commus %>% 
  group_by(community) %>% 
  summarise(neqdoc=sum(weight),
            ndoc=n())
reactable::reactable(tib_commus_prod,pagination=FALSE)
```


### Table des auteurs

```{r show_auteurs_graph}
auteurs=auteurs
reactable::reactable(auteurs %>% arrange(community),
                     groupBy="community",
                     sortable=TRUE,
                     filterable=TRUE,
                     pagination=FALSE,
                     paginateSubRows=TRUE)
```

### Table des documents\*communauté

Je retire les références citées (champ CR) et les abstracts (AB) pour un tableau un peu plus lisible...

```{r show_tib_doc_comm}
reactable::reactable(tib_doc_commus %>% select(-id_doc,-CR,-AB),
                     filterable=TRUE,
                     resizable=TRUE)
  
```

## Productivité des communautés d'auteurs au cours du temps

Les communautés d'auteurs se définissent par leurs liens de co-autorat. Il y a donc par construction une structure temporelle sous-jacente à ces communautés (deux auteurs peuvent être très similaires en termes de discipline et de thématiques mais ne pas être rattachés à la même communauté si leurs collaborations sont distantes dans le temps).

**Ce sont ces communautés qui sont le mieux à même (à mon sens) de refléter les dynamiques de recherche impulsées par les programmes de recherche...** 



```{r tib_doc_PY,fig.width=8,fig.height=6}
#| label: fig-nb_doc_par_commu
#| fig-cap: Nombre de documents publiés par les différentes communautés d'auteurs au cours du temps.
tib_community_PY=tib_doc_commus%>% 
  group_by(community,PY) %>% 
  summarise(sumw=sum(weight)) %>% 
  na.omit()
ggplot(tib_community_PY, aes(x=PY, y=sumw, fill=community))+
  geom_col()+
  facet_wrap(facets=vars(community))+
  xlab("année de publication")+
  ylab("nombre de publications")+
  theme(legend.position="none")
```

## Graphe des communautés d'auteurs

```{r auteurs_graph}
liste_auteurs_graph=auteurs %>% 
  filter(!is.na(community)) %>% 
  pull(AU)

ndoc_auteurs_graph=tib_doc_AU %>% 
  filter(AU %in% liste_auteurs_graph) %>% 
  pull(id_doc) %>% unique() %>% 
  length()
```

Le graphe ci-après représente les collaborations des `r length(liste_auteurs_graph)` auteurs qui ont été rattachés à une communauté que l'on a conservé pour la suite des analyses.

Ces `r length(liste_auteurs_graph)` auteurs représentent `r round(length(liste_auteurs_graph)/nrow(auteurs)*100,2)`% des auteurs du corpus, mais `r round(ndoc_auteurs_graph/nrow(tib_doc),2)*100`% des documents du corpus ont au moins un de ces auteurs comme n-ième auteur.

```{r graph_auteurs_show,fig.height=10,fig.width=10}
#| label: fig-communautés d'auteurs
#| fig-cap: Communautés d'auteurs définies sur la base du co-autorat et partitionnées selon la méthode de Louvain. On n'a représenté ici que les 12 communautés correspondant au poids le plus important en termes de nombre de documents. Pour chacune des 12 communautés et pour ne pas surchargé le graphe on a indiqué les 3 auteurs les plus importants en terme de nombre de documents.
auteurs_keep=auteurs %>%
  select(au,community,ndoc) %>% 
  mutate(keep=ndoc>15) %>% 
  group_by(community) %>%
  arrange(desc(ndoc)) %>% 
  mutate(rank=1:n()) %>% 
  mutate(keep=rank<=3) %>% 
  mutate(showname=case_when(keep~au,
                            !keep~NA_character_))
set.seed(1234)
tidyg=tidygraph::as_tbl_graph(p$graph) %>% 
  tidygraph::activate(nodes) %>%
  select(-community) %>% 
  filter(name %in% tolower(liste_auteurs_graph),
         deg >3) %>% 
  left_join(auteurs_keep,by=c("name"="au"))
ggraph(tidyg,layout="fr")+
  geom_edge_link(color="light grey")+
  geom_node_point(aes(color=community,size=ndoc))+
  geom_node_text(aes(label=showname),size=2)
```

## Spécificités des mots-clés par communauté d'auteurs

J'ai laissé ici ce graphique (pour la postérité on va dire) mais à mon avis dans ce contexte il est compliqué à interpréter. En effet les communautés peuvent être issues de divers horizons disciplinaires et thématiques. De ce fait les mots-clés les plus spécifiques d'une communauté peuvent être un **mélange de termes issues de disciplines ou thématiques variées** assez compliqué à interpréter pour comprendre quels sont les enjeux de recherche de cette communauté.

Du coup je propose (dans la suite du document) de caractériser les thématiques (via la classif de Reinhert) d'une manière totalement indépendante du calcul du communauté. Cela va permettre de croiser communautés et thématiques d'une manière plus aisément interprétable...

```{r spec_kw_com,fig.height=8,fig.width=6}
kw_communities=tib_doc_commus%>% 
  unnest_tokens(output="kw",input="DE",token=stringr::str_split, pattern = "; ") 
spec_com=tidy_specificities(kw_communities,cat1=kw,cat2=community,top_spec=20) %>% 
  arrange(community,desc(spec))
plot_specificities(spec_com,kw,community)
```

Les journaux associés aux différentes communautés permettent également de les caractériser. Ci-dessous, les publications scientifiques spécifiques (significatif au seuil de 1% i.e. score de spécificité \>2).

```{r spec_SO_com,fig.height=8,fig.width=6}
spec_SO=tidy_specificities(tib_doc_commus,cat1=SO,cat2=community,min_spec=2) %>% 
  arrange(community,desc(spec)) %>% 
  mutate(rank=n():1) %>% 
  select(community, SO, spec, n,rank)

ggplot(spec_SO %>% filter(spec>2),aes(x=fct_reorder(SO,rank), y=spec))+
  geom_col(aes(fill=community))+
  geom_text(aes(y=0,label=SO),hjust=0)+
  coord_flip()+
  theme(axis.text.y=element_blank())
```

# Thématiques


## Spécificités du sous-corpus SHS {#sec-spec_SHS}

Voici les termes les plus spécifiques des abstracts contenant "SOCIETY/SOCIAL/SOCIO":

```{r spec_SHS}
library(mixr)
tib_doc_ABW=tib_doc_ABW %>%
  mutate(mention_SHS=as.character(mention_SHS))
spec_SHS=tidy_specificities(tib_doc_ABW,
                   cat1=ABW,
                   cat2=mention_SHS) %>% 
  filter(mention_SHS=="TRUE") %>% 
  select(-mention_SHS) %>% 
  arrange(desc(spec))
reactable::reactable(spec_SHS %>% head(100))
```


```{r scores_SHS}
scores_SHS= spec_SHS %>% 
  mutate(spec=case_when(spec<2~0,
                        TRUE~spec)) %>% 
  select(ABW,SHS_spec=spec)
tib_doc_ABW=tib_doc_ABW %>% 
  left_join(scores_SHS, by="ABW")
tib_doc_SHS=tib_doc_ABW %>% 
  group_by(id_doc) %>% 
  summarise(SHS_spec=sum(SHS_spec,na.rm=TRUE),.groups="drop")
tib_doc_commus_SHS=tib_doc_commus %>% 
  left_join(tib_doc_SHS,by="id_doc") 
```



Quelles sont les communautés d'auteur dans lesquelles ces termes sont les plus pregnants?

```{r,fig.width=6,fig.height=4}
tib_doc_commus_SHS_summary=tib_doc_commus_SHS %>% 
  group_by(community) %>% 
  summarise(ndoc=n(),.groups="drop")
ggplot(tib_doc_commus_SHS %>% filter(!is.na(community)),
       aes(x=community,y=SHS_spec,fill=community))+
  geom_boxplot()+
  scale_y_log10()+
  geom_text(data=tib_doc_commus_SHS_summary,
            aes(label=paste0("n=",ndoc),y=1),size=3)+
  theme(legend.position="none")
```

```{r SHS_progress_in_commus}
ggplot(tib_doc_commus_SHS %>% na.omit(),
       aes(x=PY,y=SHS_spec))+
  geom_point(aes(col=community))+
  geom_smooth(method="lm",se=TRUE)+
  facet_wrap(facets=vars(community))+
  scale_x_continuous(limits=c(1990,2024))+
  scale_y_sqrt()
```


## Identification de thématiques par la méthode de Reinert

Reinert M., “Une méthode de classification descendante hiérarchique : application à l’analyse lexicale par contexte”, Cahiers de l’analyse des données, Volume 8, Numéro 2, 1983. http://www.numdam.org/item/?id=CAD_1983__8_2_187_0

Barnier J (2023). _rainette: The Reinert Method for Textual Data Clustering_. R package version 0.3.1.1,
<https://CRAN.R-project.org/package=rainette>.

```{r prepare_corpus}
tib_doc_ABc=readRDS("data/tib_doc_ABW.RDS") %>% 
  group_by(id_doc) %>% 
  summarise(ABc=paste0(ABW,collapse=" "),.groups="drop")
corpus=quanteda::corpus(tib_doc_ABc,
                        docid_field="id_doc",text_field="ABc")
tok <- quanteda::tokens(corpus, remove_numbers = TRUE)
dtm <- quanteda::dfm(tok)
dtm2 <- quanteda::dfm_trim(dtm, min_docfreq = 10)
```

```{r run_rainette}
#| label: fig-thematiques
#| fig-cap: Thématiques identifiées par la méthode de Reinert. Les termes les plus spécifiques de chaque thématique sont indiqués. Dans la suite de  l'analyse on a désigné ces thématiques par une étiquette plus synthétique (fine sediment,organic matter, delta, population_genetics, ecology_habitat, ecology_abundance, management, organic matter, glaciology, geology).

set.seed(123)
library(rainette)
res=rainette(dtm2,k=20,min_split_members=20)
#rainette_explor(res,dtm=dtm2)
rainette_plot(
  res, dtm, k = 9,
  n_terms = 20,
  free_scales = TRUE,
  measure = "chi2",
  show_negative = FALSE,
  text_size = 10
)

```

```{r tib_classes_colors}
tib_classes_colors=tibble::tibble(
  class=paste0("class_",1:9),
  color=rainette:::groups_colors(9),
)

tib_doc_commus_SHS_classes=tibble::tibble(
  id_doc=names(corpus),
  class=paste0("class_",cutree_rainette(res, k = 9))
) %>% 
  mutate(class_name=case_when(class=="class_1"~"fine sediment",#river_management",
                            class=="class_2"~"organic matter",#glaciology",
                            class=="class_3"~"delta",#geophysics",
                            class=="class_4"~"population_genetics",#ecology_communities",
                            class=="class_5"~"ecology_habitat",#"ecology_fish",
                            class=="class_6"~"ecology_abundance",#geology",
                            class=="class_7"~"management",#"organic matter",
                            class=="class_8"~"glaciology",#"sediment",
                            class=="class_9"~"geology",#"delta",
                            is.na(class)~NA_character_)) %>% 
  left_join(tib_doc_commus_SHS,by="id_doc")
```

## Nombre d'articles s'inscrivant dans les thématiques au cours du temps


```{r thematiques_PY}
#| label: fig-thematiques_temps
#| fig-cap: Nombre de publications s'inscrivant dans les différentes thématiques, au cours du temps. La courbe représente le nombre de publications attendu si les publications étaient réparties de manière homogène entre les différentes thématiques.

tib=tib_doc_commus_SHS_classes %>% 
  mutate(ntot=n()) %>% 
  group_by(PY) %>% 
  mutate(nPY=n()) %>% 
  ungroup() %>% 
  group_by(class,class_name) %>% 
  mutate(nclass=n()) %>% 
  ungroup() %>% 
  group_by(PY,nPY) %>% 
  mutate(propPY=nPY/ntot) %>%
  ungroup() %>% 
  group_by(class,class_name,nclass) %>% 
  mutate(propclass=nclass/ntot) %>% 
  ungroup() %>% 
  group_by(PY,propPY,propclass,ntot,class,class_name) %>% 
  summarise(n=n(),
            nprev=ntot*propPY*propclass,
            .groups="drop") %>% 
  unique()
ggplot(tib,aes(x=PY,y=n,fill=class))+ 
  geom_path(aes(x=PY,y=nprev))+
  geom_col(alpha=0.5)+
  facet_wrap(facets=vars(class_name))+
  scale_fill_manual(breaks=tib_classes_colors$class,
                    values=tib_classes_colors$color)+
  theme(legend.position="none")
```

# Croisement communautés d'auteurs et thématiques

```{r plot_commus_classes}
#| label: fig-thematiques_commus
#| fig-cap: Proportion des thématiques dans les différentes communautés d'auteurs.
tib=tib_doc_commus_SHS_classes %>% 
  group_by(community,class,class_name) %>% 
  tally() %>% 
  na.omit()

ggplot(tib,aes(x=class_name,y=n,fill=class))+
  facet_wrap(facets=vars(community))+
  geom_col()+
  coord_flip()+
  theme(legend.position="none")+
  scale_fill_manual(breaks=tib_classes_colors$class,
                    values=tib_classes_colors$color)
```


# Analyse des réseaux de mots-clés et de co-citation

## Co-occurrence des mots-clés

```{r calc_graph_keywords}
nw_cooc_kw <- biblioNetwork(M,
                           analysis = "co-occurrences",
                           network = "keywords",
                           sep = ";")
netstat <- networkStat(nw_cooc_kw)
```

```{r plot_graph_keywords, fig.width=8, fig.height=8}
p=networkPlot(nw_cooc_kw,
                weighted=T, n = 150,
                Title = "Co-occurence des mots-clés",
                type = "fruchterman",
                cluster="louvain",
                size=T,
                edgesize = 5,
                labelsize=0.7)
```

## Co-Citation

```{r co_citation_network, fig.width=8, fig.height=8}
M=M %>% 
  mutate(CR=str_replace(CR,"ANONYMOUS.*;","")) %>% 
  mutate(CR=str_replace(CR,"NO TITLE CAPTURED","")) 
nw_cocit_doc <- biblioNetwork(M,
                           analysis = "co-citation",
                           network = "references",
                           sep = ";")

p=networkPlot(nw_cocit_doc,
                n = 150,
                Title = "Co-Citation Network",
                type = "auto",
                size=T,
                cluster="louvain",
                remove.multiple=FALSE,
                labelsize=0.7,
                edgesize = 5,
                label.n=30)
```

## Structure conceptuelle basée sur les mots-clés

```{r conceptual_structure,fig.width=8, fig.height=8}
CS <- conceptualStructure(M,
                          field="ID",
                          method="MCA",
                          minDegree=10,
                          clust=8,
                          stemming=FALSE,
                          labelsize=10,
                          documents=3,
                          graph=FALSE)
CS$graph_terms
CS$graph_dendrogram
```
