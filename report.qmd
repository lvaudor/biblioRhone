---
title: "BiblioRhone"
format: 
  html:
    code-fold: true
    toc: true
    toc_float: true
editor: visual
execute:
  message: false
  warning: false
---

```{r load_packages}
# Chargement des packages et des données
library(tidyverse)
library(bibliometrix)
```

```{r load_data_bibliometrix,message=FALSE, warning=FALSE}
file <- "data/savedrecs.bib"
if(!file.exists("data/data_trans/M.RDS")){
  M <- convert2df(file = file,
                  dbsource = "isi",
                  format = "bibtex")
  saveRDS(M,"data/data_trans/M.RDS")
}
if(!file.exists("data/data_trans/results.RDS")){
  results <- biblioAnalysis(M, sep = ";")
  saveRDS(results,"data/data_trans/results.RDS")
}
M=readRDS("data/data_trans/M.RDS")
results=readRDS("data/data_trans/results.RDS")
```

```{r tib_doc}
if(!file.exists("data/data_trans/tib_doc.RDS")){
  tib_doc=M %>%
    rownames_to_column(var="id_doc") %>% 
    as_tibble()
  saveRDS(tib_doc,"data/data_trans/tib_doc.RDS")
}
tib_doc=readRDS("data/data_trans/tib_doc.RDS")
```

```{r tib_auteur}
if(!file.exists("data/data_trans/tib_auteur.RDS")){
  tib_auteur=tib_doc %>% 
    group_by(id_doc) %>% 
    nest() %>% 
    mutate(data=purrr::map(data,
                           ~mutate(.x,
                                   AU=str_split(AU,";")))) %>%
    mutate(data=purrr::map(data,
                           ~unnest(.x, cols=c("AU")))) %>% 
    unnest(cols="data") %>% 
    mutate(AU_rank=1:n()) %>% 
    ungroup() 
  saveRDS(tib_auteur,"data/data_trans/tib_auteur.RDS")
}
tib_auteur=readRDS("data/data_trans/tib_auteur.RDS")
```

```{r tib_motscles}
if(!file.exists("data/data_trans/tib_motscles.RDS")){
  tib_motscles= tib_doc %>% 
    group_by(id_doc) %>% 
    nest() %>% 
    mutate(data=purrr::map(data,
                           ~mutate(.x,DE=str_split(DE,";")))) %>% 
    mutate(data=purrr::map(data,
                           ~unnest(.x, cols="DE"))) %>% 
    unnest(cols="data") %>% 
    ungroup() 
  saveRDS(tib_motscles,"data/data_trans/tib_motscles.RDS")
}
tib_motscles=readRDS("data/data_trans/tib_motscles.RDS")
```

# Analyses simples, "à plat"

### Auteurs

- **ndoc** nombre de documents (dans ce corpus):
- **ncit** nombre de citations (globales)
- **ndoc_1st** nombre de documents en tant que 1er auteur
- **ncit_1st** nombre de citations en tant que 1er auteur
- **ncit_loc**: nombre de citations locales (i.e. par les document de ce corpus)

```{r locallyCitedAuthors}
if(!file.exists("data/data_trans/aut_loc.RDS")){
    LCR=localCitations(M)
    #LCR$Authors$Author liste des auteurs cités dans le champ M$CR
    #Combien de fois chacun de ces auteurs apparaît dans M$CR?
    #Attention ce résultat ne correspond pas à celui renvoyé par localCitations() voir objet LCR
    aut_loc=LCR$Authors %>% 
      as_tibble() %>% 
      select(Author) %>% 
      filter(!(Author %in% c("DE","LE","VAN","[ANONYMOUS] A"))) %>% 
      mutate(ncit_loc=purrr::map_int(Author, ~length(which(str_detect(M$CR,.x)))))
    saveRDS(aut_loc,"data/data_trans/aut_loc.RDS")
}
```

```{r auteurs}
if(!file.exists("data/data_trans/auteurs.csv")){
aut_loc=readRDS("data/data_trans/aut_loc.RDS")
auteurs=tib_auteur %>% 
  group_by(AU) %>% 
  mutate(ndoc=n(),
         ncit=sum(TC)) %>%
  filter(AU_rank==1) %>% 
  summarise(ndoc=unique(ndoc),
            ncit=unique(ncit),
            ndoc_1st=n(),
            ncit_1st=sum(TC)) %>%
  ungroup() %>% 
  left_join(aut_loc,by=c("AU"="Author")) %>% 
  arrange(desc(ndoc)) 
  write_csv2(auteurs, "data/data_trans/auteurs.csv")
}
auteurs=read_csv2("data/data_trans/auteurs.csv")
reactable::reactable(auteurs,
                     filterable=TRUE)
```

### Sources

-   ndoc: nombre de documents
-   ncit: nombre de citations (totales)

```{r sources}
if(!file.exists("data/data_trans/sources.csv")){
  sources=tib_doc %>% 
    group_by(SO) %>% 
    summarise(ndoc=n(),
              ncit=sum(TC)) %>%
    arrange(desc(ndoc))
  write_csv2(sources,"data/data_trans/sources.csv")
}
sources=read_csv2("data/data_trans/sources.csv")

reactable::reactable(sources,
                     filterable=TRUE)
```

### Documents

(Top 100 basé sur le nombre de citations, TC)

```{r top_100_articles}
show_docs=tib_doc %>% 
  arrange(desc(TC)) %>% 
  select(AU,TC,PY,TI,SO) %>% 
  head(100)
reactable::reactable(show_docs,
                     filterable=TRUE)
```

### Références

Les articles du corpus font référence à des documents locaux (du corpus) ou externes.

*Attention* Une partie (minime: \~0.7%) de ces références est mal renseignée par WOS. Celles qui sont correctement renseignées de manière correcte le sont de telle sorte qu'il est difficile de faire une jointure pour retrouver les références locales.

```{r bad_citations}
cit=citations(M)
cit$Cited %>% as_tibble %>%
  summarise(nref=sum(n),
            nref_distinctes=n(),
            nref_pb=length(which(str_detect(CR,"ANONYMOUS"))))
```

Top 100 des articles les plus cités **par** le corpus:

```{r citations}
citations=cit$Cited %>%
  as_tibble() %>% 
  filter(!str_detect(CR,"ANONYMOUS"))
reactable::reactable(citations %>% head(100),
                     filterable=TRUE)
```

### Affiliations

bibliometrix comprend des fonctions permettant d'extraire automatiquement les éléments d'affiliation distincts et les références mais ça fonctionne moyen (de fait il est déjà assez difficile d'en faire sens au niveau de l'export WOS...)

```{r affiliations}
aff=results$Affiliations %>%
  as_tibble() %>% 
  head(n=50)
reactable::reactable(aff)
```

Il est ainsi assez difficile de travailler sur les affiliations de manière "non dirigée"... Par exemple pour les publis Hervé et en filtrant pour garder les publis récentes (\>2005) on a déjà 34 affiliations formulées de manière différentes (tout est mélangé pour les différents auteurs des articles) et en fonction du champ l'info principale n'est pas toujours la même (ici pas de mention de EVS par ex.).

<!-- ```{r aff_piegay} -->

<!-- aff_piegay=tib_auteur %>%  -->

<!--   filter(AU=="PIEGAY H" & PY>2005) %>%  -->

<!--   select(affiliations) %>%  -->

<!--   unique() -->

<!-- reactable::reactable(aff_piegay) -->

<!-- ``` -->

Par contre on pourrait imaginer lister un certain nombre de structures (CNRS, EVS, LBBE, LEHNA, etc) et tenter de détecter à partir de cet ensemble quels auteurs/publis s'y rattachent...

### Financement

Des infos sont enregistrées dans la base de données WOS concernant les programmes de recherche et les sources de financement. On peut récupérer ces renseignements pour environ un tiers des documents. Si on veut s'en servir il y aura un peu de nettoyage à faire...

```{r funding}
if(!file.exists("data/data_trans/bibtib.RDS")){
    bib=bibtex::read.bib("data/savedrecs.bib")
    bibtib=tibble(WOS_ID=names(bib),
                  funding_text=NA,
                  funding_acknowledgement=NA)
    for(i in 1:length(bib)){
      biblist=unlist(bib[i])
      var_text=paste0(bibtib$WOS_ID[i],".funding-text")
      var_ackn=paste0(bibtib$WOS_ID[i],".funding-acknowledgement")
      if(var_text %in% names(biblist)){
        bibtib$funding_text[i]=biblist[[var_text]]
      }else{
        bibtib$funding_text[i]=NA
      }
      if(var_ackn %in% names(biblist)){
        bibtib$funding_acknowledgement[i]=biblist[[var_ackn]]
      }else{
        bibtib$funding_acknowledgement[i]=NA
      }
    }
    bibtib =bibtib %>% 
      mutate(funding_text=str_replace_all(funding_text,"\\{\\[\\}","[")) %>% 
      mutate(funding_acknowledgement=str_replace_all(funding_acknowledgement,"\\{\\[\\}","["))%>% 
      mutate(funding_text=str_replace_all(funding_text,"``|\\{''\\}|\\n","")) %>% 
      mutate(funding_acknowledgement=str_replace_all(funding_acknowledgement,"``|\\{''\\}|\\n",""))%>% 
      mutate(funding_text=str_replace_all(funding_text,"\\s+"," ")) %>% 
      mutate(funding_acknowledgement=str_replace_all(funding_acknowledgement,"\\s+"," "))
  saveRDS(bibtib,"data/data_trans/bibtib.RDS")
}
bibtib=readRDS("data/data_trans/bibtib.RDS")
```

```{r financeurs}
financeurs=bibtib %>% 
  filter(!is.na(funding_acknowledgement)) %>% 
  group_by(funding_acknowledgement) %>% 
  summarise(ndoc=n()) %>% 
  arrange(desc(ndoc))
reactable::reactable(financeurs,
                     filterable=TRUE)
```

```{r ZABR}
financeurs %>% 
  mutate(ZABR=str_detect(funding_acknowledgement,
                         "ZABR|Zone Atelier Bassin du Rh.ne|GRAIE|OHM|OSR")) %>% 
  group_by(ZABR) %>% 
  summarise(n=n())
```


## Nombre de publis par année (dans le corpus)

```{r ndoc_per_year}
ggplot(tib_doc,
       aes(x=PY))+
  geom_bar()+
  xlab("année de publication")+ylab("nombre de publications")
```

```{r aut_prod_over_time}
topAU <- authorProdOverTime(M, k = 20, graph = TRUE)
```

# Graphes biblio

`biblioNetwork()` a deux arguments principaux

- L'argument **analysis** peut prendre les valeurs "co-citation", "coupling", "collaboration", or "co-occurrences". (co-citation=ils sont cités par un même article, coupling=ils citent un même article)
- L'argument **network** peut prendre les valeurs "authors", "references", "sources", "countries", "universities", "keywords", "author_keywords", "titles" and "abstracts".

## Collaborations (auteurs)

```{r calc_collaboration_graph}
nw_coll_auth <- biblioNetwork(M,
                           analysis = "collaboration",
                           network = "authors",
                           sep = ";")

```

```{r plot_collaboration_graph, fig.width=8,fig.height=8}
p=networkPlot(nw_coll_auth,
            normalize="association",
            n = 250,
            Title = "Collaborations",
            type = "fruchterman",
            size=5,
            size.cex=T,
            labelsize=0.5,
            label.n=50,
            label.cex=F,
            alpha=0.5,
            remove.isolates=TRUE,
            edges.min=1)

```

## Co-Citation

```{r co_citation_network, fig.width=8, fig.height=8}
M=M %>% 
  mutate(CR=str_replace(CR,"ANONYMOUS.*;","")) %>% 
  mutate(CR=str_replace(CR,"NO TITLE CAPTURED","")) 
nw_cocit_doc <- biblioNetwork(M,
                           analysis = "co-citation",
                           network = "references",
                           sep = ";")

p=networkPlot(nw_cocit_doc,
                n = 150,
                Title = "Co-Citation Network",
                type = "auto",
                size=T,
                cluster="louvain",
                remove.multiple=FALSE,
                labelsize=0.7,
                edgesize = 5,
                label.n=30)
```

## Co-occurrence des mots-clés

```{r calc_graph_keywords}
nw_cooc_kw <- biblioNetwork(M,
                           analysis = "co-occurrences",
                           network = "keywords",
                           sep = ";")
netstat <- networkStat(nw_cooc_kw)
```

```{r plot_graph_keywords, fig.width=8, fig.height=8}
p=networkPlot(nw_cooc_kw,
                weighted=T, n = 150,
                Title = "Co-occurence des mots-clés",
                type = "fruchterman",
                cluster="louvain",
                size=T,
                edgesize = 5,
                labelsize=0.7)
```



<!-- ## Historical Direct Citation Network -->

<!-- The historiographic map is a graph proposed by E. Garfield (2004) to represent a chronological network map of most relevant direct citations resulting from a bibliographic collection. -->

<!-- Garfield, E. (2004). Historiographic mapping of knowledge domains literature. Journal of Information Science, 30(2), 119-145. -->

<!-- The function generates a chronological direct citation network matrix which can be plotted using histPlot: -->

<!-- ## Create a historical citation network -->

<!-- ```{r histnetwork,fig.height=10,fig.width=10} -->

<!-- histResults <- histNetwork(M, min.citations = 1, sep = ";") -->

<!-- net <- histPlot(histResults, n=150, size = 1, labelsize=5, verbose=FALSE) -->

<!-- net$g+theme(legend.position="none") -->

<!-- ``` -->

## Structure conceptuelle basée sur les mots-clés

```{r conceptual_structure,fig.width=8, fig.height=8}
CS <- conceptualStructure(M,
                          field="ID",
                          method="MCA",
                          minDegree=10,
                          clust=8,
                          stemming=FALSE,
                          labelsize=10,
                          documents=3,
                          graph=FALSE)
CS$graph_terms
CS$graph_dendrogram
```

# Analyse textuelle des abstracts


```{r tib_textes}
library(tidytext)
### Mise en forme de la base
tib_doc_light=tib_doc %>% 
   select(id_doc,TI,AU,SO,DT,DE,TC,PY,AB)
if(!file.exists("data/data_trans/tib_lemma_cl.RDS")){
  ### Tokenisation, lemmatisation:
  tib_lemma=tib_doc_light %>% 
    unnest_tokens(word,AB,token="words")
  
  lex_en=mixr::get_lexicon("en")
  tib_lemma_cl=left_join(tib_lemma, lex_en,by="word") %>% 
    filter(type %in% c("nom","ver","adj"))
  saveRDS(tib_lemma_cl,"data/data_trans/tib_lemma_cl.RDS")
}
tib_lemma_cl=readRDS("data/data_trans/tib_lemma_cl.RDS")


if(!file.exists("data/data_trans/tib_sparse.RDS")){
  ### mise en forme pour STM
  tib_sparse=tib_lemma_cl %>% 
    group_by(lemma) %>% # compte pour chaque lemme...
    mutate(n=n()) %>% # ...son nombre d'occurrences puis
    filter(n>20) %>%  # retire ceux représentés moins de 20 fois dans le corpus
    ungroup() %>% 
    cast_sparse(row=TI, column=lemma, value=n)
  saveRDS(tib_sparse,"data/data_trans/tib_sparse.RDS")
}
tib_sparse=readRDS("data/data_trans/tib_sparse.RDS")
```

## STM

```{r stm}
library(stm)
if(!file.exists("data/data_trans/topic_model.RDS")){
  set.seed(123)
  topic_model<-stm(tib_sparse,K=8, verbose=FALSE)
  saveRDS(topic_model,"data/data_trans/topic_model.RDS")
}
topic_model=readRDS("data/data_trans/topic_model.RDS")
```

## Explore thématiques

```{r thematiques}
thematiques=tidytext::tidy(topic_model, matrix="beta") %>% 
  group_by(topic) %>% 
  slice_max(beta,n=20) %>%  
  mutate(rank=row_number()) %>% 
  arrange(topic,desc(beta)) %>% 
  ungroup()
```

```{r plot_thematiques, fig.width=8, fig.height=8}
ggplot(thematiques  %>%
         mutate(topic=as.factor(topic)) %>%
         mutate(term=tidytext::reorder_within(term,by=beta,within=topic)),
       aes(x=beta,y=term, fill=topic))+
  geom_bar(stat="identity")+
    facet_wrap(facets=vars(topic), scales="free")+
    theme(legend.position="none")+
  tidytext::scale_y_reordered()
```

```{r thematiques_resumees}
thematiques=thematiques %>% 
  group_by(topic) %>% 
  nest()%>%  
  summarise(topic_terms=map(data, ~paste(.$term,collapse=", "))) %>% 
  unnest(cols=c(topic_terms)) %>% 
  mutate(topic_short=case_when(topic==1~"hydrologie",
                               topic==2~"transport sédimentaire",
                               topic==3~"modélisation",
                               topic==4~"écologie",
                               topic==5~"biochimie",
                               topic==6~"quantification",
                               topic==7~"changements,risques",
                               topic==8~"étude régionale"))
```

```{r tib_meta_thematiques}

tib_gamma <- tidy(topic_model, matrix = "gamma") %>% 
  arrange(document,desc(gamma))

tib_doc_th=tib_doc_light  %>%
  mutate(document=1:n()) %>% 
  left_join(tib_gamma,by="document") %>% 
  left_join(thematiques,by="topic") 


ggplot(tib_doc_th%>% 
         group_by(PY,topic,topic_short) %>% 
         summarise(sgamma=sum(gamma),
                   n=n()) %>% 
         ungroup() %>% 
         mutate(sgamma=sgamma/n) %>% 
         na.omit(),
       aes(x=PY,y=sgamma,col=topic_short))+
  geom_smooth()
```


```{r}
tib_auteur_th=tib_auteur %>% 
  left_join(tib_doc_th %>% select(id_doc,topic,gamma,topic_terms,topic_short),
            by="id_doc") %>% 
  group_by(AU) %>% 
  mutate(ndoc=n()) %>%
  ungroup() %>% 
  group_by(AU,topic,topic_short) %>% 
  summarise(s=sum(gamma),
            ndoc=unique(ndoc)) %>% 
  mutate(s=s/ndoc) %>% 
  arrange(desc(ndoc)) %>% 
  ungroup() %>% 
  na.omit()
top_auteurs=tib_auteur_th %>% group_by(AU) %>% summarise(n=unique(ndoc)) %>% top_n(10) %>% pull(AU)
ggplot(tib_auteur_th %>% filter(AU %in% top_auteurs),
       aes(x=topic_short,y=s,fill=factor(topic_short)))+
  geom_col()+
  facet_wrap(facets=vars(AU))+
  coord_flip()
```

